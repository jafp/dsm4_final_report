\chapter{Signal with Memory - Random Processes}
\label{ch:part2}

\section{a. Autokorrelation}
I denne opgave skal vi se på forskellige tilfældigt genererede signaler og deres relation til hukommelse. Vi skal stifte bekendtskab med Markov modellen som vi vil gøre brug af.\\
\subsection{Markov modellen}
Markov modellen er en måde hvor på vi kan lave en stokastisk proces hvor tilstanden udelukkende bestemmes af den tidligere tilstand. Man kan overføre metoden til den fysiske verden ved at udtrykke det med: Jo højere sandsynligheden er for at tilstanden skifter, jo højere er frekvensen fra modellen. Markov modellen har stor relation til hukommelse i en proces. Hvis sandsynligheden er 50$\%$ for at tilstanden skifter er det dermed et udtryk for, at der ingen hukommelse er i processen da der er lige stor sandsynlighed for et tilstands skifte, hvis sandsynligheden går mod 1 eller 0 vil hukommelsen være større i processen og dermed vil sandsynligheden være mindre for et tilstands skifte.

 På figure \ref{fig:part2_1} er en Markov overfødselstilstands matrix hvori sandsynligheden for tilstandsskift er beskrevet:  

På figure \ref{fig:part2_2} er et Markov diagram som visuelt beskriver Markov matrixen:

 \begin{figure}[!h]
	\centering
	\subfloat[Markov matrix ]{%
		\includegraphics[width=0.2\textwidth]{resources/part2_markov_matrix}
		\label{fig:part2_1}}
	\subfloat[Markov diagram]{%
		\includegraphics[width=0.4\textwidth]{resources/part2_markov_diagram}
		\label{fig:part2_2}}
	\caption{Markov model med tilstandsmatrix og tilhørende diagram}
	\label{fig:part2_markov}
\end{figure}
 

\subsection{Autokorrelation}
Autokorrelation af en tilfældig proces beskriver værdierne i den tilfældige proces til forskellige tidspunkter. Denne metode kan benyttes til at finde hukommelse i en proces. 
Det er ofte relevant at undersøge en tidsserie for vedravenhed, dvs. om værdierne i en tidsserie er afhængige af de foregående værdier. Til dette formål benyttes autokorrelationsfunktionen.
Autokorrelationsfunktionen kan beskrives som:\\
Hvis
\begin{equation}
 y[n] = x[n]
\end{equation}
Så er autokorrelationsfunktionen: 
\begin{equation}
r_{xx}=\sum_{n = - \infty}^{\infty}x[n+k]x[n]=\sum^{\infty}_{n = -\infty}x[n]x[n\cdot k] 
\end{equation}

Vi vil se på hvordan autokorrelationen ser ud på en enkelt tilfældig proces og tilsvarende hvordan den arter sig ved 
gennemsnittet af mange gentagelser af samme proces.
Autokorrelationsfunktionen for en realisering af processen er en stokastisk signal i sig selv - mens autokorrelation af processen er et helt deterministisk signal.\\


Vi vil lave forsøget tre slags signaler  

\begin{enumerate}
	\item Ensartet fordelt pseudotilfældige numre (rand i matlab)   figur \ref{fig:part2_3}
	\item Normalfordelt pseudotilfældige numre (randn i matlab)figur\ref {fig:part2_4}
	\item 1. ordens Markov model med to tilstande uden hukommelse. figur \ref{fig:part2_5}
	\item 1. ordens Markov model med to tilstande med hukommelse. figur \ref{fig:part2_6} 
\end{enumerate}

På begge figure på \ref{fig:part2_ran} og \ref{fig:part2_markov}, er den øverste illustration af realiseringen af processen. Den midterste illustration er af en enkelt realisering af det autokorrelateret signal og den nederste er autokorrelateringen  af gennemsnittet af 100 realisering.  
 \begin{figure}[!h]
	\centering
	\subfloat[ Ensartet fordelt pseudotilfældige numre]{%
		\includegraphics[width=0.6\textwidth]{resources/part2_rand}
		\label{fig:part2_3}}
	\subfloat[normalfordelt pseudotilfældige numre]{%
		\includegraphics[width=0.6\textwidth]{resources/part2_randn}
		\label{fig:part2_4}}
	\caption{ Ensartet fordelt pseudotilfældige og normalfordelt pseudotilfældige numre med autokorrlation }
	\label{fig:part2_ran}
\end{figure}

 \begin{figure}[!h]
	\centering
	\subfloat[Markov model uden hukommelse]{%
		\includegraphics[width=0.55\textwidth]{resources/part2_markov_uden}
		\label{fig:part2_5}}
	\subfloat[Markov model med hukommelse]{%
		\includegraphics[width=0.55\textwidth]{resources/part2_markov_med}
		\label{fig:part2_6}}
	\caption{Markov model med og uden hukommelse }
	\label{fig:part2_markov}
\end{figure}
Hvis vi ser på de nederste tre plots hvor der ikke forefindes hukommelse, kan vi se at autokorrelationen er en deltafunktion. Dette indikerer af der ikke er hukommelse i processen. Det sidste plot hvor der er hukommelse figur\ref{fig:part2_6} er der ikke tale om en delta funktion og det kan på denne måde identificeres, at der er hukommelse i processen. 


\section{b. Entropi }
Entropi er et mål i bit, som beskriver uforudsigelighed af informationsindhold i en proces.

 \begin{figure}[!h]
	\centering
	\includegraphics[width=0.6\textwidth]{resources/part2_entropi_diagram}
	\caption{Markov overførselsdiagram for entropi }
	\label{fig:part2_7}
\end{figure}
Og tilsvarende kan vi opstille en markov overgangs matrix:

\[ \left[ \begin{array}{ccc}
P(0|0) & p(0|1)  \\
P(1|0) & P(1|1) \end{array} \right]\] 

Vi skal udfra viden om entropi, finde entropien for et system med og et uden hukommelse.\\
Vi finder entropien ved:
\begin{equation}
H(X) = P(0)H(X|0)+P(1)H(X|1)
\end{equation}
Hvor
\begin{equation}
H(X|0)=p(0|0)log_2 \bigg(\frac{1}{P(0|0)}\bigg)+P(1|0)log_2\bigg(\frac{1}{P(1|0)}\bigg)
\end{equation}
\begin{equation}
H(X|1)=p(0|1)log_2 \bigg(\frac{1}{P(0|1)}\bigg)+P(1|1)log_2\bigg(\frac{1}{P(1|1)}\bigg)
\end{equation}

P(0) og P(1) finder vi ved at løse disse to ligninger med de to ubekendte:

\begin{equation}
P(0) = P(0|0)P(0)+P(1|0)P(1)
\end{equation}

\begin{equation}
P(1)=P(1|0)P(0)+P(0|1)P(1)
\end{equation}

Hvor
\begin{equation}
P(0)+P(1)=1
\end{equation}

Vi laver en proces med hukommelse og finder entropien for denne tilfældige proces:\\ vi opstiller en Markov overførings matrix for processen:

\[ \left[ \begin{array}{ccc}
P(0|0) = 0.92 & p(1|0) = 0.08   \\
P(0|1) = 0.12  & P(1|1) = 0.88  \end{array} \right]\] 

Vi udregner $P(X|0)$ og $P(X|1)$:

\begin{equation}
H(X|0)=0.92log_2 \bigg(\frac{1}{0.92}\bigg)+0.08log_2\bigg(\frac{1}{0.08}\bigg) = 0.402
\end{equation}
\begin{equation}
H(X|1)=0.12log_2 \bigg(\frac{1}{0.12}\bigg)+0.88log_2\bigg(\frac{1}{0.88}\bigg) = 0.529
\end{equation}

Derefter finder vi $P(0)$ og $P(1)$:

\begin{equation}
P(0) = 0.6 \\,\\P(1) = 0.4
\end{equation}

Vi bruger ligning 2.1 til at finde $H(X)$:

 \begin{equation}
H(X) = 0.6\cdot 0.402+0.4 \cdot 0.529 = 0.453 bit/symbol
\end{equation} 



\begin{equation}
H(x)_{hukommelse}<H(x)_{ingen hukommelse}
\end{equation}



\section{c.}

Wiener-Khinchin Teorem hedder, at energi tæthedspektrummet af en tilfældig proces er fouier transformationen af autokorrelationens funktionen. Det vil med andre ord betyde at vi kan lave et energi spektrogram ved at lave en fouier transformation på den autokorrelaieret proces.
 
Vi kan illustrer det således:\\

\begin{tikzpicture}
  \centering
  \matrix (m) [matrix of math nodes,row sep=6em,column sep=7em,minimum width=4em] {
     x[n] & X(e^{j\omega}) \\
     r_{xx}[k] & R_{xx}(e^{j\omega}) = |X(e^{j\omega})|^2 \\};
  \path[-stealth]
    (m-1-1) edge node [left] {Autokorrlation} 
    (m-2-1) edge node [above] {DTFT} (m-1-2)
    (m-2-1) edge node [below] {DTFT} node [above] {} (m-2-2)
    (m-1-2) edge node [right] {$|\cdot|^2$} (m-2-2);
            %edge [dashed,-] (m-2-1);
\end{tikzpicture}


Hvis vi først ser på en realetaion af en tilfældig proces (1. orden markov med 2 tilstande) med og uden hukommelse:

De øverste plots er af selve den tilfældige proces hvor der tydeligt ses, at den ene højre er med hukommelse hvor imod den venstre er uden. De nederste to plots viser spektrummet af de samme tilfældige proces hvor fft en er fundet med gentaget 1024 gange og derefter summeret og gennemsnittet fundet.

 På plot (b) hvor der ikke forefindes hukommelse ses det på spektrumet a der er Gaussian hvid støj som er alle frekvenser. Der imod på spektrummet med hukommelse (b) ser vi en lav pass filter lignende karakteristik.  
 \begin{figure}[!h]
	\centering
	\subfloat[med hukommelse]{%
		\includegraphics[width=0.55\textwidth]{resources/part2_spec_med.png}
		\label{fig:part2_8}}
	\subfloat[uden hukommelse]{%
		\includegraphics[width=0.55\textwidth]{resources/part2_spec_uden.png}
		\label{fig:part2_9}}
	\caption{Realisation af en tilfældig processer med og uden hukommelse og spektrum af samme tilfældig processer  }
	\label{fig:part2_markov}
\end{figure}

